instance_specs:
  max_price_usd_hour: 1.0 
  memory_gb: 16

work_dir: "llama_weights"

setup:
    run:
    - "sudo apt install -y docker.io git curl"
    - "cd llama_weights && bash llama_7b.sh" # download weights using script (can also leave them in work_dir after downloading locally)
    - "sudo docker run -v . ghcr.io/ggerganov/llama.cpp:full --all-in-one "." 7B" # generate ggml from weights 

task:
  run:
    - "" # run inference server 